{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cdb6e8b-9ded-4a3d-93e2-a55d9fd57e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import glob\n",
    "import clip\n",
    "from itertools import chain\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "# import zipfile\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "# from functools import reduce\n",
    "import torch.nn as nn\n",
    "# from einops import rearrange, repeat\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from imgaug import augmenters as iaa\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "# from skimage import io, img_as_float\n",
    "import timm\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score, accuracy_score, roc_auc_score, precision_recall_curve, f1_score\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0899a791-3e14-4127-9ab9-79bb0cff335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "from utils import class_labels, get_dataset, get_transforms, DeepFakeSet, get_class_based_training_data\n",
    "from models import clipmodel, dinov2, CLIPModelOhja\n",
    "from trainer import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93c487ed-92aa-4088-805a-198b6137cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2abf22f7-4391-4cf6-a91a-09449a12b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 17\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e522b31-d409-46f4-8c83-770334c4a1f3",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47922c3c-8a24-4b28-a435-0b272bf4b227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP OpenAI state dict loaded!\n",
      "==\n"
     ]
    }
   ],
   "source": [
    "model_ours = clipmodel()\n",
    "model_ours.load_state_dict(torch.load('weights/CLIP_linear_prob_2_epoch_100k_vit_large_with_augs.pth'), strict=True)\n",
    "model_ours.eval()\n",
    "model_ours.cuda()\n",
    "print('==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b206c862-008a-440c-b875-eab66cc717df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "395274f4-5266-4637-9a2e-d2c0ed8ad3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def update_and_save_evaluation(model_name, dataset_name, accuracy, f1_score, average_precision):\n",
    "    global model_evaluations\n",
    "    \n",
    "    # Check if the model key exists in the dictionary\n",
    "    if model_name not in model_evaluations:\n",
    "        model_evaluations[model_name] = {}\n",
    "    \n",
    "    # Check if the dataset key exists for the given model\n",
    "    if dataset_name not in model_evaluations[model_name]:\n",
    "        model_evaluations[model_name][dataset_name] = {}\n",
    "    \n",
    "    # Update evaluation results\n",
    "    model_evaluations[model_name][dataset_name][\"accuracy\"] = accuracy\n",
    "    model_evaluations[model_name][dataset_name][\"f1_score\"] = f1_score\n",
    "    model_evaluations[model_name][dataset_name][\"average_precision\"] = average_precision\n",
    "\n",
    "    save_file_name = model_name.split('/')[-1].split('.')[0]+'.json'\n",
    "    \n",
    "    # Save the updated dictionary to a JSON file\n",
    "    with open(save_file_name, \"w\") as json_file:\n",
    "        json.dump(model_evaluations, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3e3bab6-be73-48ee-92bb-340437bd6b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['progan', 'biggan', 'cyclegan', 'eg3d', 'gaugan',  'stargan', 'stylegan', 'stylegan2', 'stylegan3', \n",
    "                 'dalle2', 'glide_50_27', 'glide_100_10', 'glide_100_27', 'guided', 'ldm_100', 'ldm_200', 'ldm_200_cfg',\n",
    "                 'sd_512x512', 'sdxl', 'taming', 'deepfake', 'firefly', 'midjourney_v5', 'dalle3', 'faceswap']\n",
    "\n",
    "model_names = ['weights/CLIP_linear_prob_2_epoch_10k_vit_large_with_augs.pth', 'weights/CLIP_linear_prob_2_epoch_20k_vit_large_with_augs.pth',\n",
    "              'weights/CLIP_linear_prob_2_epoch_30k_vit_large_with_augs.pth', 'weights/CLIP_linear_prob_2_epoch_40k_vit_large_with_augs.pth']\n",
    "\n",
    "model_names = ['weights/CLIP_linear_prob_2_epoch_100k_vit_large_with_augs.pth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b770e768-1362-4b3e-892e-6e065243b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"Datasets/ICMRDataset/test/deepfake_eval/\"\n",
    "image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.gif', '*.bmp', '*.tiff', '*.tif']  # Add more extensions as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab7cce7f-bb50-4a6d-82d1-c4ee479a8f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = 2.0\n",
    "model_evaluations = {}\n",
    "tfms = transforms.Compose([\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "        ])\n",
    "\n",
    "for model_name in model_names:\n",
    "    model_ours = clipmodel()\n",
    "    model_ours.load_state_dict(torch.load(model_name), strict=True)\n",
    "    model_ours.eval()\n",
    "    model_ours.cuda()\n",
    "    print('==Loaded ' + model_name.split('/')[-1].split('.')[0] + '==')\n",
    "    for dataset in dataset_names:\n",
    "        print('Evaluating on: ' + dataset)\n",
    "        labels_map = [\"real\", \"fake\"]\n",
    "        count = 0\n",
    "        all_images = []\n",
    "        predicted_labels = []\n",
    "        true_labels = []\n",
    "        predicted_probs = []\n",
    "\n",
    "        real_image_directory = dataset_path + dataset + '/images/val/n01440764/'\n",
    "        fake_image_directory = dataset_path + dataset + '/images/val/n01443537/'\n",
    "        \n",
    "        images = []\n",
    "        for extension in image_extensions:\n",
    "            images.extend(glob.glob(os.path.join(real_image_directory, extension)))\n",
    "            images.extend(glob.glob(os.path.join(fake_image_directory, extension)))\n",
    "        images = sorted(images)\n",
    "        images = [path.replace('\\\\','/') for path in images]\n",
    "        print('Num. Images: ', len(images))\n",
    "        y_pred = []\n",
    "        for image in images:\n",
    "            img = cv2.imread(image)\n",
    "            # img = cv2_jpg(img, 50)\n",
    "            # image = add_noise(image, 0.4)\n",
    "            # gaussian_blur(img, sig)\n",
    "            img = Image.fromarray(img)\n",
    "            img = img.convert('RGB')\n",
    "            # img = Image.open(image)\n",
    "            img = tfms(img)\n",
    "            y_true = []\n",
    "            with torch.no_grad():\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model_ours(img.unsqueeze(0).to(device))\n",
    "                    y_pred.extend(outputs.sigmoid().flatten().tolist())\n",
    "                    # y_true.extend(label.flatten().tolist())\n",
    "    \n",
    "            for idx in torch.topk(outputs[0], k=1).indices.tolist():\n",
    "                prob = torch.softmax(outputs[0], 0)[idx].item()\n",
    "                if labels_map[idx] == 'real':\n",
    "                    # print(\"real\")\n",
    "                    predicted_labels.append(0)\n",
    "                    predicted_probs.append(1 - prob)\n",
    "                else:\n",
    "                    # print(\"fake\")\n",
    "                    predicted_labels.append(1)\n",
    "                    predicted_probs.append(prob)\n",
    "            \n",
    "            # print(image.split('/')[-2])\n",
    "            if 'n01440764' in image.split('/')[-2]:\n",
    "                true_labels.append(0)\n",
    "            else:\n",
    "                true_labels.append(1)\n",
    "        \n",
    "        average_precision = 100 * average_precision_score(true_labels, predicted_probs)\n",
    "        accuracy = 100 * accuracy_score(true_labels, predicted_labels)\n",
    "        macro_f1 = 100.0 * f1_score(true_labels, predicted_labels, average=\"macro\")\n",
    "        \n",
    "        update_and_save_evaluation(model_name, dataset, accuracy, macro_f1, average_precision)\n",
    "        print('--------------')\n",
    "        \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ad849472-6390-4c01-919f-1f61990a1a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8296772251656449"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(true_labels, predicted_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a17cdfce-3680-4dab-99b2-ad8c7530b97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6784655300222387"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385094d3-76f0-4533-8280-bb9d15c96ddf",
   "metadata": {},
   "source": [
    "# Full Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d073da0-7698-4411-81d0-b58918e80a6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPModelOhja(\n",
       "  (model): CLIP(\n",
       "    (visual): VisionTransformer(\n",
       "      (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "      (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): Sequential(\n",
       "          (0): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (12): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (13): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (14): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (15): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (16): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (17): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (18): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (19): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (20): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (21): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (22): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (23): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (token_embedding): Embedding(49408, 768)\n",
       "    (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CLIPModelOhja()\n",
    "model.fc.load_state_dict(torch.load('weights/fc_weights.pth'), strict=True)\n",
    "model.eval()\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ede9ae3-d5f1-4581-8d79-9ab544571616",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['progan', 'biggan', 'cyclegan', 'eg3d', 'gaugan',  'stargan', 'stylegan', 'stylegan2', 'stylegan3', \n",
    "                 'dalle2', 'glide_50_27', 'glide_100_10', 'glide_100_27', 'guided', 'ldm_100', 'ldm_200', 'ldm_200_cfg',\n",
    "                 'sd_512x512', 'sdxl', 'taming', 'deepfake', 'firefly', 'midjourney_v5', 'dalle3']\n",
    "dataset_names = ['faceswap']\n",
    "                #  'eg3d', 'stylegan3'] 'dalle2', 'deepfake', 'glide_50_27', 'glide_100_10', 'glide_100_27',\n",
    "                # 'guided', 'ldm_100', 'ldm_200', 'ldm_200_cfg',\n",
    "# dataset_names = ['firefly', 'midjourney_v5', 'dalle3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f71f44c-bf5a-4d53-b71b-2dd03d09fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def update_and_save_evaluation(model_name, dataset_name, accuracy, f1_score, average_precision):\n",
    "    global model_evaluations\n",
    "    \n",
    "    # Check if the model key exists in the dictionary\n",
    "    if model_name not in model_evaluations:\n",
    "        model_evaluations[model_name] = {}\n",
    "    \n",
    "    # Check if the dataset key exists for the given model\n",
    "    if dataset_name not in model_evaluations[model_name]:\n",
    "        model_evaluations[model_name][dataset_name] = {}\n",
    "    \n",
    "    # Update evaluation results\n",
    "    model_evaluations[model_name][dataset_name][\"accuracy\"] = accuracy\n",
    "    model_evaluations[model_name][dataset_name][\"f1_score\"] = f1_score\n",
    "    model_evaluations[model_name][dataset_name][\"average_precision\"] = average_precision\n",
    "    \n",
    "    # Save the updated dictionary to a JSON file\n",
    "    with open(\"ojha_model_evaluations_FACESWAP.json\", \"w\") as json_file:\n",
    "        json.dump(model_evaluations, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "212b8d56-a3ac-4a4e-b0b6-1052aff01d17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800\n",
      "2800\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "model_evaluations = {}\n",
    "tfms = transforms.Compose([\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "        ])\n",
    "\n",
    "for dataset in dataset_names:\n",
    "    labels_map = [\"real\", \"fake\"]\n",
    "    count = 0\n",
    "    all_images = []\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    predicted_probs = []\n",
    "    \n",
    "    images = sorted(glob.glob('../Datasets/ICMRDataset/test/deepfake_eval/'+dataset+'/images/val/n01440764/'+'*.jpg'))\n",
    "    fake_images = sorted(glob.glob('../Datasets/ICMRDataset/test/deepfake_eval/'+dataset+'/images/val/n01443537/'+'*.jpg'))\n",
    "\n",
    "    if len(images) == 0:\n",
    "        images = sorted(glob.glob('../Datasets/ICMRDataset/test/deepfake_eval/'+dataset+'/images/val/n01440764/'+'*.png'))\n",
    "    if len(fake_images) == 0:\n",
    "        fake_images = sorted(glob.glob('../Datasets/ICMRDataset/test/deepfake_eval/'+dataset+'/images/val/n01443537/'+'*.png'))\n",
    "            \n",
    "    # images = sorted(glob.glob('../CoOp/data/ImageNet/images/val/n01440764/*.jpg'))\n",
    "    # fake_images = sorted(glob.glob('../CoOp/data/ImageNet/images/val/n01443537/*.png'))\n",
    "    \n",
    "    print(len(images))\n",
    "    print(len(fake_images))\n",
    "    \n",
    "    # np.random.shuffle(fake_images)\n",
    "    # np.random.shuffle(fake_images)\n",
    "    \n",
    "    all_images = images\n",
    "    all_images.extend(fake_images)\n",
    "    \n",
    "    all_images = [path.replace('\\\\','/') for path in all_images]\n",
    "    y_pred = []\n",
    "    for image in all_images:\n",
    "        img = cv2.imread(image)\n",
    "        # img = cv2_jpg(img, 50)\n",
    "        # image = add_noise(image, 0.4)\n",
    "        img = Image.fromarray(img)\n",
    "        img = img.convert('RGB')\n",
    "        # img = Image.open(image)\n",
    "        img = tfms(img)\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(img.unsqueeze(0).to(device))\n",
    "                y_pred.extend(outputs.sigmoid().flatten().tolist())\n",
    "                # y_true.extend(label.flatten().tolist())\n",
    "    \n",
    "        # print(outputs.sigmoid().flatten())\n",
    "        if outputs.sigmoid().flatten() < 0.5:\n",
    "            # print(\"real\")\n",
    "            predicted_labels.append(0)\n",
    "            predicted_probs.append(outputs.sigmoid().flatten().cpu().numpy())\n",
    "        else:\n",
    "            # print(\"fake\")\n",
    "            predicted_labels.append(1)\n",
    "            predicted_probs.append(outputs.sigmoid().flatten().cpu().numpy())\n",
    "        \n",
    "        # print(image.split('/')[-2])\n",
    "        if 'n01440764' in image.split('/')[-2]:\n",
    "            true_labels.append(0)\n",
    "        else:\n",
    "            true_labels.append(1)\n",
    "        \n",
    "    \n",
    "    # y_true, y_pred = np.array(true_labels), np.array(y_pred)\n",
    "    # train with compression and blur\n",
    "    average_precision = 100 * average_precision_score(true_labels, predicted_probs)\n",
    "    accuracy = 100 * accuracy_score(true_labels, predicted_labels)\n",
    "    macro_f1 = 100.0 * f1_score(true_labels, predicted_labels, average=\"macro\")\n",
    "    \n",
    "    update_and_save_evaluation('OjhaCLIP', dataset, accuracy, macro_f1, average_precision)\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97329ef6-f785-4f9d-b3be-7a169aeff874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.81490083543112"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "616d0bed-ed6f-45bf-b8f4-c2e879230b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.39999999999999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4faf3ea-5d34-4458-81a0-916a6e448863",
   "metadata": {},
   "source": [
    "# Full Evaluation Wang et. el."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9fa894a-6c54-44cc-b50f-c94ddc25589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.resnet import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdd2c76b-c2d3-4544-99cd-ce7075c6f24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['progan', 'biggan', 'cyclegan', 'eg3d', 'gaugan',  'stargan', 'stylegan', 'stylegan2', 'stylegan3', \n",
    "                 'dalle2', 'glide_50_27', 'glide_100_10', 'glide_100_27', 'guided', 'ldm_100', 'ldm_200', 'ldm_200_cfg',\n",
    "                 'sd_512x512', 'sdxl', 'taming', 'deepfake', 'firefly', 'midjourney_v5', 'dalle3']\n",
    "dataset_names = ['faceswap']\n",
    "                #  'eg3d', 'stylegan3'] 'dalle2', 'deepfake', 'glide_50_27', 'glide_100_10', 'glide_100_27',\n",
    "                # 'guided', 'ldm_100', 'ldm_200', 'ldm_200_cfg',\n",
    "# dataset_names = ['firefly', 'midjourney_v5', 'dalle3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6befebcc-7b3f-4286-b9ec-547c2ade6860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def update_and_save_evaluation(model_name, dataset_name, accuracy, f1_score, average_precision):\n",
    "    global model_evaluations\n",
    "    \n",
    "    # Check if the model key exists in the dictionary\n",
    "    if model_name not in model_evaluations:\n",
    "        model_evaluations[model_name] = {}\n",
    "    \n",
    "    # Check if the dataset key exists for the given model\n",
    "    if dataset_name not in model_evaluations[model_name]:\n",
    "        model_evaluations[model_name][dataset_name] = {}\n",
    "    \n",
    "    # Update evaluation results\n",
    "    model_evaluations[model_name][dataset_name][\"accuracy\"] = accuracy\n",
    "    model_evaluations[model_name][dataset_name][\"f1_score\"] = f1_score\n",
    "    model_evaluations[model_name][dataset_name][\"average_precision\"] = average_precision\n",
    "    \n",
    "    # Save the updated dictionary to a JSON file\n",
    "    with open(\"wang_model_evaluations_FACESWAP.json\", \"w\") as json_file:\n",
    "        json.dump(model_evaluations, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "976adeec-f36e-4db9-a0c4-33db0fae6284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet50(num_classes=1)\n",
    "state_dict = torch.load('weights/blur_jpg_prob0.5.pth', map_location='cpu')\n",
    "model.load_state_dict(state_dict['model'])\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32bc1450-4fe7-420d-8e48-57fa174586c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800\n",
      "2800\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "model_evaluations = {}\n",
    "tfms = transforms.Compose([\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        ])\n",
    "\n",
    "for dataset in dataset_names:\n",
    "    labels_map = [\"real\", \"fake\"]\n",
    "    count = 0\n",
    "    all_images = []\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    predicted_probs = []\n",
    "    \n",
    "    images = sorted(glob.glob('../Datasets/ICMRDataset/test/deepfake_eval/'+dataset+'/images/val/n01440764/'+'*.jpg'))\n",
    "    fake_images = sorted(glob.glob('../Datasets/ICMRDataset/test/deepfake_eval/'+dataset+'/images/val/n01443537/'+'*.jpg'))\n",
    "\n",
    "    if len(images) == 0:\n",
    "        images = sorted(glob.glob('../Datasets/ICMRDataset/test/deepfake_eval/'+dataset+'/images/val/n01440764/'+'*.png'))\n",
    "    if len(fake_images) == 0:\n",
    "        fake_images = sorted(glob.glob('../Datasets/ICMRDataset/test/deepfake_eval/'+dataset+'/images/val/n01443537/'+'*.png'))\n",
    "            \n",
    "    # images = sorted(glob.glob('../CoOp/data/ImageNet/images/val/n01440764/*.jpg'))\n",
    "    # fake_images = sorted(glob.glob('../CoOp/data/ImageNet/images/val/n01443537/*.png'))\n",
    "    \n",
    "    print(len(images))\n",
    "    print(len(fake_images))\n",
    "    \n",
    "    # np.random.shuffle(fake_images)\n",
    "    # np.random.shuffle(fake_images)\n",
    "    \n",
    "    all_images = images\n",
    "    all_images.extend(fake_images)\n",
    "    \n",
    "    all_images = [path.replace('\\\\','/') for path in all_images]\n",
    "    y_pred = []\n",
    "    for image in all_images:\n",
    "        img = cv2.imread(image)\n",
    "        # img = cv2_jpg(img, 50)\n",
    "        # image = add_noise(image, 0.4)\n",
    "        img = Image.fromarray(img)\n",
    "        img = img.convert('RGB')\n",
    "        # img = Image.open(image)\n",
    "        img = tfms(img)\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(img.unsqueeze(0).to(device))\n",
    "                y_pred.extend(outputs.sigmoid().flatten().tolist())\n",
    "                # y_true.extend(label.flatten().tolist())\n",
    "    \n",
    "        # print(outputs.sigmoid().flatten())\n",
    "        if outputs.sigmoid().flatten() < 0.5:\n",
    "            # print(\"real\")\n",
    "            predicted_labels.append(0)\n",
    "            predicted_probs.append(outputs.sigmoid().flatten().cpu().numpy())\n",
    "        else:\n",
    "            # print(\"fake\")\n",
    "            predicted_labels.append(1)\n",
    "            predicted_probs.append(outputs.sigmoid().flatten().cpu().numpy())\n",
    "        \n",
    "        # print(image.split('/')[-2])\n",
    "        if 'n01440764' in image.split('/')[-2]:\n",
    "            true_labels.append(0)\n",
    "        else:\n",
    "            true_labels.append(1)\n",
    "    \n",
    "    # y_true, y_pred = np.array(true_labels), np.array(y_pred)\n",
    "    # train with compression and blur\n",
    "    average_precision = 100 * average_precision_score(true_labels, predicted_probs)\n",
    "    accuracy = 100 * accuracy_score(true_labels, predicted_labels)\n",
    "    macro_f1 = 100.0 * f1_score(true_labels, predicted_labels, average=\"macro\")\n",
    "    \n",
    "    update_and_save_evaluation('WangResNet0.5', dataset, accuracy, macro_f1, average_precision)\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcb8d39e-25f1-4535-9980-4d73d1b163a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet50(num_classes=1)\n",
    "state_dict = torch.load('weights/blur_jpg_prob0.1.pth', map_location='cpu')\n",
    "model.load_state_dict(state_dict['model'])\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3a4b087-eb66-4aef-8bb9-7d665f9fb495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "4000\n",
      "--------------\n",
      "2000\n",
      "2000\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n",
      "5000\n",
      "5000\n",
      "--------------\n",
      "1999\n",
      "1999\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n",
      "950\n",
      "950\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n",
      "2698\n",
      "2698\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n",
      "1000\n",
      "1000\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# model_evaluations = {}\n",
    "tfms = transforms.Compose([\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        ])\n",
    "\n",
    "for dataset in dataset_names:\n",
    "    labels_map = [\"real\", \"fake\"]\n",
    "    count = 0\n",
    "    all_images = []\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    predicted_probs = []\n",
    "    \n",
    "    images = sorted(glob.glob('../Datasets/ICMRDataset/test/deepfake_eval/'+dataset+'/images/val/n01440764/'+'*.jpg'))\n",
    "    fake_images = sorted(glob.glob('../Datasets/ICMRDataset/test/deepfake_eval/'+dataset+'/images/val/n01443537/'+'*.jpg'))\n",
    "\n",
    "    if len(images) == 0:\n",
    "        images = sorted(glob.glob('../Datasets/ICMRDataset/test/deepfake_eval/'+dataset+'/images/val/n01440764/'+'*.png'))\n",
    "    if len(fake_images) == 0:\n",
    "        fake_images = sorted(glob.glob('../Datasets/ICMRDataset/test/deepfake_eval/'+dataset+'/images/val/n01443537/'+'*.png'))\n",
    "            \n",
    "    # images = sorted(glob.glob('../CoOp/data/ImageNet/images/val/n01440764/*.jpg'))\n",
    "    # fake_images = sorted(glob.glob('../CoOp/data/ImageNet/images/val/n01443537/*.png'))\n",
    "    \n",
    "    print(len(images))\n",
    "    print(len(fake_images))\n",
    "    \n",
    "    # np.random.shuffle(fake_images)\n",
    "    # np.random.shuffle(fake_images)\n",
    "    \n",
    "    all_images = images\n",
    "    all_images.extend(fake_images)\n",
    "    \n",
    "    all_images = [path.replace('\\\\','/') for path in all_images]\n",
    "    y_pred = []\n",
    "    for image in all_images:\n",
    "        img = cv2.imread(image)\n",
    "        # img = cv2_jpg(img, 50)\n",
    "        # image = add_noise(image, 0.4)\n",
    "        img = Image.fromarray(img)\n",
    "        img = img.convert('RGB')\n",
    "        # img = Image.open(image)\n",
    "        img = tfms(img)\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(img.unsqueeze(0).to(device))\n",
    "                y_pred.extend(outputs.sigmoid().flatten().tolist())\n",
    "                # y_true.extend(label.flatten().tolist())\n",
    "    \n",
    "        # print(outputs.sigmoid().flatten())\n",
    "        if outputs.sigmoid().flatten() < 0.5:\n",
    "            # print(\"real\")\n",
    "            predicted_labels.append(0)\n",
    "            predicted_probs.append(outputs.sigmoid().flatten().cpu().numpy())\n",
    "        else:\n",
    "            # print(\"fake\")\n",
    "            predicted_labels.append(1)\n",
    "            predicted_probs.append(outputs.sigmoid().flatten().cpu().numpy())\n",
    "        \n",
    "        # print(image.split('/')[-2])\n",
    "        if 'n01440764' in image.split('/')[-2]:\n",
    "            true_labels.append(0)\n",
    "        else:\n",
    "            true_labels.append(1)\n",
    "    \n",
    "    # y_true, y_pred = np.array(true_labels), np.array(y_pred)\n",
    "    # train with compression and blur\n",
    "    average_precision = 100 * average_precision_score(true_labels, predicted_probs)\n",
    "    accuracy = 100 * accuracy_score(true_labels, predicted_labels)\n",
    "    macro_f1 = 100.0 * f1_score(true_labels, predicted_labels, average=\"macro\")\n",
    "    \n",
    "    update_and_save_evaluation('WangResNet0.1', dataset, accuracy, macro_f1, average_precision)\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b7a3a1-f094-4b4e-b2ac-35083035668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "python test.py --gpu_ids 0 --which_epoch best_val --partition test --dataset_name celebahq-pgan-pretrained --real_im_path Datasets/ICMRDataset/test/deepfake_eval/'+biggan+'/images/val/n01440764 --fake_im_path Datasets/ICMRDataset/test/deepfake_eval/'+biggan+'/images/val/n01443537 --train_config checkpoints/gp1-gan-winversion_seed0_xception_block2_constant_p20/opt.yml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5691363c-2d7b-4c20-9b15-eb8dcf514652",
   "metadata": {},
   "outputs": [],
   "source": [
    "python test_runs.py checkpoints/gp1-gan-winversion_seed0_xception_block2_constant_p20 gen_models test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea5241b-c4d8-49de-a161-92adf4cda4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
